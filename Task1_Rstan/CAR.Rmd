---
title: "CAR"
author: "ZQXB4"
output: html_document
---

```{r}
# Load the packages with library()
library("sf")
library("tmap")
library("spdep")
library("rstan")
library("geostan")
library("SpatialEpi")
library("tidybayes")
library("tidyverse")
```

```{r}
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

```{r}
setwd("D:/Desktop/GEOG0125/Assessment/RStan")    
```

```{r}
# load the shape files
england_LA_shp <- read_sf("Dataset/shapefile/England Local Authority Shapefile.shp")
england_Region_shp <- read_sf("Dataset/shapefile/England Regions Shapefile.shp")
```

```{r}
# load the covid deaths csv dataset
covid_death <- read.csv("Dataset/cleaned data/cleaned_data.csv")
```


1 Data Preparation in RStudio

```{r}
colnames(covid_death)
```

```{r}
covid_death <- covid_death[, !colnames(covid_death) %in% c("X")]
```


```{r}
## Calculation for expected numbers
# calculate the expected number of cases
covid_death$ExpectedNum <- round(expected(population = covid_death$Population, cases = covid_death$covid, n.strata = 1), 0)
```

```{r}
## Converting the spatial adjacency matrix to nodes & edges
# merge the attribute table to the shapefile
spatial.data <- merge(england_LA_shp, covid_death, by.x = c("LAD21CD", "LAD21NM"), by.y = c("LADCD", "Area.Name.x"))
```

```{r}
# reordering the columns
spatial.data <- spatial.data[, c(3,1,2,5,4,9,6,7,8,10)]
# need to be coerced into a spatial object
sp.object <- as(spatial.data, "Spatial")
```

```{r}
# needs to be coerced into a matrix object
adjacencyMatrix <- shape2mat(sp.object)
# we extract the components for the ICAR model
extractComponents <- prep_icar_data(adjacencyMatrix)
```

```{r}
# performing the extraction
n <- as.numeric(extractComponents$group_size)
nod1 <- extractComponents$node1
nod2 <- extractComponents$node2
n_edges <- as.numeric(extractComponents$n_edges)
```

```{r}
colnames(spatial.data)
```


```{r}
## Create the dataset to be compiled in Stan
y <- spatial.data$covid
x1 <- as.integer(spatial.data$health)
x2 <- as.integer(spatial.data$income)
x3 <- as.integer(spatial.data$environment)
e <- spatial.data$ExpectedNum
```

```{r}
# put all components into a list object
stan.spatial.dataset <- list(N=n, N_edges=n_edges, node1=nod1, node2=nod2, Y=y, X1=x1, X2=x2, X3=x3, E=e)
```


2 Creating the script for the Spatial ICAR smoothed model


3 Compiling Stan code for Spatial ICAR modelling
```{r}
## Printing of the global results
icar_poisson_fit = stan("D:/Desktop/GEOG0125/Week8/Dataset for Week 8/icar_poisson_model.stan", data=stan.spatial.dataset, iter=20000, chains=6, verbose = FALSE)
```

```{r}
# remove that annoying scientific notation
options(scipen = 999)
summary(icar_poisson_fit, pars=c("alpha", "beta1", "beta2", "beta3", "sigma"), probs=c(0.025, 0.975))$summary
```

```{r}
# show first 6 rows only instead of the full 299
head(summary(icar_poisson_fit, pars=c("phi"), probs=c(0.025, 0.975))$summary)
```

```{r}
print(icar_poisson_fit, pars=c("alpha", "beta1", "beta2","beta3","sigma", "phi"), probs=c(0.025, 0.975))
```


```{r}
## Rapid diagnostics of the rHATs
# diagnostic check on the rHats - put everything into a data frame
diagnostic.checks <- as.data.frame(summary(icar_poisson_fit, pars=c("alpha", "beta1", "beta2", "beta3", "sigma", "phi", "lp__"), probs=c(0.025, 0.5, 0.975))$summary)
# create binary variable
diagnostic.checks$valid <- ifelse(diagnostic.checks$Rhat < 1.1, 1, 0)
# tabulate it
table(diagnostic.checks$valid)
```

```{r}
## Extraction of the area-specific relative risks
# show first 6 rows only instead of the full 307
head(summary(icar_poisson_fit, pars=c("mu"), probs=c(0.025, 0.975))$summary)
```

```{r}
# extraction key posterior results for the generated quantities 
relativeRisk.results <- as.data.frame(summary(icar_poisson_fit, pars=c("mu"), probs=c(0.025, 0.975))$summary)
head(relativeRisk.results)
```

```{r}
# now cleaning up this table up
# first, insert clean row numbers to new data frame
row.names(relativeRisk.results) <- 1:nrow(relativeRisk.results)
# second, rearrange the columns into order
relativeRisk.results <- relativeRisk.results[, c(1,4,5,7)]
# third, rename the columns appropriately
colnames(relativeRisk.results)[1] <- "rr"
colnames(relativeRisk.results)[2] <- "rrlower"
colnames(relativeRisk.results)[3] <- "rrupper"
colnames(relativeRisk.results)[4] <- "rHAT"

# view clean table 
head(relativeRisk.results)
```

```{r}
# proceed to generate risk maps
# align the results to the areas in shapefile
spatial.data$rr <- relativeRisk.results[, "rr"]
spatial.data$rrlower <- relativeRisk.results[, "rrlower"]
spatial.data$rrupper <- relativeRisk.results[, "rrupper"]
```

```{r}
# create categories to define if an area has significant increase or decrease in risk, or nothing all 
spatial.data$Significance <- NA
spatial.data$Significance[spatial.data$rrlower<1 & spatial.data$rrupper>1] <- 0      # NOT SIGNIFICANT
spatial.data$Significance[spatial.data$rrlower==1 | spatial.data$rrupper==1] <- 0    # NOT SIGNIFICANT
spatial.data$Significance[spatial.data$rrlower>1 & spatial.data$rrupper>1] <- 1      # SIGNIFICANT INCREASE
spatial.data$Significance[spatial.data$rrlower<1 & spatial.data$rrupper<1] <- -1     # SIGNIFICANT DECREASE
```

```{r}
## Mapping of RR and significance
# For map design for the relative risk -- we want to understand or get a handle on what the distribution for risks look like
# this would inform we of how to create the labelling for the legends when make a map in tmap
summary(spatial.data$rr)
```

```{r}
hist(spatial.data$rr)
```

```{r}
# creating the labels
RiskCategorylist <- c(">0.0 to 0.25", "0.26 to 0.50", "0.51 to 0.75", "0.76 to 0.99", "1.00 & <1.01",
                      "1.01 to 1.10", "1.11 to 1.25", "1.26 to 1.50", "1.51 to 1.75", "1.76 to 2.00", "2.01 to 3.00")
```

```{r}
RRPalette <- c("#65bafe","#98cffe","#cbe6fe","#dfeffe","white","#fed5d5","#fcbba1","#fc9272","#fb6a4a","#de2d26","#a50f15")
```

```{r}
# categorising the risk values to match the labelling in RiskCategorylist object
spatial.data$RelativeRiskCat <- NA
spatial.data$RelativeRiskCat[spatial.data$rr>= 0 & spatial.data$rr <= 0.25] <- -4
spatial.data$RelativeRiskCat[spatial.data$rr> 0.25 & spatial.data$rr <= 0.50] <- -3
spatial.data$RelativeRiskCat[spatial.data$rr> 0.50 & spatial.data$rr <= 0.75] <- -2
spatial.data$RelativeRiskCat[spatial.data$rr> 0.75 & spatial.data$rr < 1] <- -1
spatial.data$RelativeRiskCat[spatial.data$rr>= 1.00 & spatial.data$rr < 1.01] <- 0
spatial.data$RelativeRiskCat[spatial.data$rr>= 1.01 & spatial.data$rr <= 1.10] <- 1
spatial.data$RelativeRiskCat[spatial.data$rr> 1.10 & spatial.data$rr <= 1.25] <- 2
spatial.data$RelativeRiskCat[spatial.data$rr> 1.25 & spatial.data$rr <= 1.50] <- 3
spatial.data$RelativeRiskCat[spatial.data$rr> 1.50 & spatial.data$rr <= 1.75] <- 4
spatial.data$RelativeRiskCat[spatial.data$rr> 1.75 & spatial.data$rr <= 2.00] <- 5
spatial.data$RelativeRiskCat[spatial.data$rr> 2.00 & spatial.data$rr <= 10] <- 6
```

```{r}
# check to see if legend scheme is balanced - if a number is missing that categorisation is wrong!
table(spatial.data$RelativeRiskCat)
```

```{r}
# map of relative risk
rr_map <- tm_shape(spatial.data) + 
  tm_fill("RelativeRiskCat", style = "cat", title = "Relavtive Risk", palette = RRPalette, labels = RiskCategorylist) +
  tm_shape(england_Region_shp) + tm_polygons(alpha = 0.05) + tm_text("name", size = "AREA") +
  tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
  tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
```

```{r}
# map of significance regions
sg_map <- tm_shape(spatial.data) + 
  tm_fill("Significance", style = "cat", title = "Significance Categories", 
          palette = c("#33a6fe", "white", "#fe0000"), labels = c("Significantly low", "Not Significant", "Significantly high")) +
  tm_shape(england_Region_shp) + tm_polygons(alpha = 0.10) + tm_text("name", size = "AREA") +
  tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
  tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
```

```{r}
# create side-by-side plot
tmap_arrange(rr_map, sg_map, ncol = 2, nrow = 1)
```

```{r}
## Extracting and mapping of the exceedance probabilities
# extract the exceedence probabilities from the icar_possion_fit object
# compute the probability that an area has a relative risk ratio > 1.0
threshold <- function(x){mean(x > 1.00)}
excProbrr <- icar_poisson_fit %>% spread_draws(mu[i]) %>% 
  group_by(i) %>% summarise(mu=threshold(mu)) %>%
  pull(mu)
```

```{r}
# insert the exceedance values into the spatial data frame
spatial.data$excProb <- excProbrr
```

```{r}
# create the labels for the probabilities
ProbCategorylist <- c("<0.01", "0.01-0.09", "0.10-0.19", "0.20-0.29", "0.30-0.39", "0.40-0.49","0.50-0.59", "0.60-0.69", "0.70-0.79", "0.80-0.89", "0.90-0.99", "1.00")
```

```{r}
# categorising the probabilities in bands of 10s
spatial.data$ProbCat <- NA
spatial.data$ProbCat[spatial.data$excProb>=0 & spatial.data$excProb< 0.01] <- 1
spatial.data$ProbCat[spatial.data$excProb>=0.01 & spatial.data$excProb< 0.10] <- 2
spatial.data$ProbCat[spatial.data$excProb>=0.10 & spatial.data$excProb< 0.20] <- 3
spatial.data$ProbCat[spatial.data$excProb>=0.20 & spatial.data$excProb< 0.30] <- 4
spatial.data$ProbCat[spatial.data$excProb>=0.30 & spatial.data$excProb< 0.40] <- 5
spatial.data$ProbCat[spatial.data$excProb>=0.40 & spatial.data$excProb< 0.50] <- 6
spatial.data$ProbCat[spatial.data$excProb>=0.50 & spatial.data$excProb< 0.60] <- 7
spatial.data$ProbCat[spatial.data$excProb>=0.60 & spatial.data$excProb< 0.70] <- 8
spatial.data$ProbCat[spatial.data$excProb>=0.70 & spatial.data$excProb< 0.80] <- 9
spatial.data$ProbCat[spatial.data$excProb>=0.80 & spatial.data$excProb< 0.90] <- 10
spatial.data$ProbCat[spatial.data$excProb>=0.90 & spatial.data$excProb< 1.00] <- 11
spatial.data$ProbCat[spatial.data$excProb == 1.00] <- 12
```

```{r}
# check to see if legend scheme is balanced
table(spatial.data$ProbCat)
```

```{r}
# map of exceedance probabilities
tm_shape(spatial.data) + 
  tm_fill("ProbCat", style = "cat", title = "Probability", palette = "GnBu", labels = ProbCategorylist) +
  tm_shape(england_Region_shp) + tm_polygons(alpha = 0.05, border.col = "black") + tm_text("name", size = "AREA") +
  tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 0.8, legend.text.size = 0.7) +
  tm_compass(position = c("right", "top")) + tm_scale_bar(position = c("right", "bottom"))
```

